{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# We import pandas because we have a very large data set. It's a csv file with all data for all columns present (al large table). Pandas is ideal for this scenario.\n",
    "\n",
    "import numpy as np\n",
    "# We import numpy because we might want to use the built in functions to see the correlation of multiple columns in the data frame.\n",
    "\n",
    "import statsmodels.api as sm\n",
    "# We use that statsmodels library to validate the np and sklearn libraries\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# We might not need this because pandas has its own .plot() function, but just in case we want to plot something specific.\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# Because we want to use regression on the data set we will use the science kit linear_model and import LinearRegression.\n",
    "\n",
    "from sklearn import metrics\n",
    "# We might want to see how well variables correlate with eachother, we will use the the metrics library as well.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/preprocessed_data.csv\")\n",
    "df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will start with a simple linear regression. We will predict `B_avg_DISTANCE_landed` by avg by `B_avg_DISTANCE_att`.\n",
    "# This way we can see if or what impact the B_avg_DISTANCE_landed has on the B_win_by_KO/TKO.\n",
    "\n",
    "# Independent variable x\n",
    "x = df[\"B_avg_DISTANCE_att\"].to_numpy().reshape((-1, 1))\n",
    "\n",
    "# Dependent variable y\n",
    "y = df[\"B_avg_DISTANCE_landed\"].to_numpy().reshape((-1, 1))\n",
    "\n",
    "model = LinearRegression().fit(x, y)\n",
    "\n",
    "y_predict = model.predict(x)\n",
    "\n",
    "print(f\"b0: {model.intercept_}\")\n",
    "print(f\"b1: {model.coef_}\")\n",
    "# print(f\"y_predict: {y_predict}\")\n",
    "\n",
    "det = metrics.r2_score(y, y_predict)\n",
    "print(f\"The determination coefficient is: {det}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another way to do this is using the statmodels api\n",
    "x = sm.add_constant(x)\n",
    "model = sm.OLS(y, x)\n",
    "results = model.fit()\n",
    "results.summary()\n",
    "\n",
    "# We can observe that the r-sqared with both methods is about 0.886."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's do the basic multivariate linear regression.\n",
    "# We want to predict if either red or blue wins based on the fight data of that particular fight. This means we will use:\n",
    "# Winner as red = 1, and blue = 0\n",
    "# We will use the statsmodels api becuase it gives both the r^2 and the adjusted r^2\n",
    "\n",
    "def set_y(outcomes):\n",
    "    y = []\n",
    "\n",
    "    for i in outcomes:\n",
    "        if i == \"Red\":\n",
    "            y.append(1)\n",
    "        elif i == \"Blue\":\n",
    "            y.append(0)\n",
    "        else:\n",
    "            raise Exception(f\"Can't parse value {i}\")\n",
    "\n",
    "    return y\n",
    "    \n",
    "\n",
    "outcomes = df[\"Winner\"].to_numpy().reshape((-1, 1))\n",
    "\n",
    "y = set_y(outcomes)\n",
    "\n",
    "x = df[[\"B_avg_BODY_att\",\n",
    "\"B_avg_BODY_landed\",\n",
    "\"B_avg_CLINCH_att\",\n",
    "\"B_avg_CLINCH_landed\",\n",
    "\"B_avg_DISTANCE_att\",\n",
    "\"B_avg_DISTANCE_landed\", \n",
    "\"B_avg_GROUND_att\",\n",
    "\"B_avg_GROUND_landed\",\n",
    "\"B_avg_HEAD_att\",\n",
    "\"B_avg_HEAD_landed\",\n",
    "\"B_avg_LEG_att\",\n",
    "\"B_avg_LEG_landed\",\n",
    "\"B_avg_PASS\",\n",
    "\"B_avg_REV\", \n",
    "\"B_avg_SIG_STR_att\",\n",
    "\"B_avg_SIG_STR_landed\", \n",
    "\"B_avg_SIG_STR_pct\",\n",
    "\"B_avg_SUB_ATT\",\n",
    "\"B_avg_TD_att\",\n",
    "\"B_avg_TD_landed\",\n",
    "\"B_avg_TD_pct\", \n",
    "\"B_avg_TOTAL_STR_att\",\n",
    "\"B_avg_TOTAL_STR_landed\", \n",
    "\"R_avg_BODY_att\",\n",
    "\"R_avg_BODY_landed\",\n",
    "\"R_avg_CLINCH_att\",\n",
    "\"R_avg_CLINCH_landed\",\n",
    "\"R_avg_DISTANCE_att\",\n",
    "\"R_avg_DISTANCE_landed\", \n",
    "\"R_avg_GROUND_att\",\n",
    "\"R_avg_GROUND_landed\",\n",
    "\"R_avg_HEAD_att\",\n",
    "\"R_avg_HEAD_landed\",\n",
    "\"R_avg_LEG_att\",\n",
    "\"R_avg_LEG_landed\",\n",
    "\"R_avg_PASS\",\n",
    "\"R_avg_REV\", \n",
    "\"R_avg_SIG_STR_att\",\n",
    "\"R_avg_SIG_STR_landed\", \n",
    "\"R_avg_SIG_STR_pct\",\n",
    "\"R_avg_SUB_ATT\",\n",
    "\"R_avg_TD_att\",\n",
    "\"R_avg_TD_landed\",\n",
    "\"R_avg_TD_pct\", \n",
    "\"R_avg_TOTAL_STR_att\",\n",
    "\"R_avg_TOTAL_STR_landed\"]]\n",
    "\n",
    "x = sm.add_constant(x)\n",
    "model = sm.OLS(y, x)\n",
    "res = model.fit()\n",
    "res.summary()\n",
    "\n",
    "# prediction = model.predict(x)\n",
    "# print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can check the results using the sklearn library\n",
    "model = LinearRegression().fit(x, y)\n",
    "y_predict = model.predict(x)\n",
    "det = metrics.r2_score(y, y_predict)\n",
    "\n",
    "\n",
    "print(f\"b0: {model.intercept_}\")\n",
    "print(f\"b1: {model.coef_}\")\n",
    "print(f\"det: {det}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can test if normalizing the data helps with the determination coeficient\n",
    "\n",
    "for r in x.columns:\n",
    "    x[r] = x[r].apply(lambda v: (v - x[r].min()) / (x[r].max() - x[r].min()))\n",
    "\n",
    "x.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see what de determination coeficient is now\n",
    "# But first we have to remove the const column, because it contains NaN's and it is not relevant to y\n",
    "\n",
    "x = x.drop([\"const\"], axis=1)\n",
    "\n",
    "model = LinearRegression().fit(x, y)\n",
    "y_predict = model.predict(x)\n",
    "det = metrics.r2_score(y, y_predict)\n",
    "\n",
    "\n",
    "print(f\"b0: {model.intercept_}\")\n",
    "print(f\"b1: {model.coef_}\")\n",
    "print(f\"det: {det}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This does not appear to change the determination coeficient. I think it's because, even though we changed the numbers to a different scale, the porportions are still the same.\n",
    "# We can also try the z-score, and see how that affects the determination coeficient.\n",
    "from scipy.stats.mstats import zscore\n",
    "\n",
    "zx = zscore(x)\n",
    "zy = zscore(y)\n",
    "\n",
    "sm.OLS(zy, zx).fit().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also look for multicolinearity.\n",
    "# This allows us to see which independent variable has the most inpact on the prediction.\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# We will need a column of constants to set the intercept term in the equation.\n",
    "x[\"const\"] = 1\n",
    "print(x.head(10))\n",
    "\n",
    "vif = pd.DataFrame()\n",
    "vif[\"VarianceInflationFactor\"] = [variance_inflation_factor(x.values, i) for i in range(x.shape[1])]\n",
    "vif[\"Variables\"] = x.columns\n",
    "\n",
    "vif.head(10)\n",
    "print(x.columns[7])\n",
    "print(x.columns[19])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There appears to be a strong colinearify between average tagke down landed, and average ground landed.\n",
    "# This is pretty logical, considering the chanses of you hitting the opponsent on the ground are very high if you have taken your opponent down, and pretty low if you have not taken your opponent down.\n",
    "# This is why I will remove average ground landed, since it is much more important to knop how good a fighter is in taking the opponent down.\n",
    "\n",
    "x = x.drop([\"B_avg_GROUND_landed\", \"R_avg_GROUND_landed\"], axis=1)\n",
    "\n",
    "sm.OLS(y, x).fit().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This does not appear to have effect on the predictabily of the match. This can also be explained because if you would view take downs and ground attacks as one, it would not make much difference in the outcome of the match.\n",
    "\n",
    "# For this reason we will try a different technique.\n",
    "# We will attempt to make this more predictable by using machine learning to solve our problem.\n",
    "\n",
    "# Step 1: Create test and training datasets\n",
    "# We already have x and y, so we just need to split those.\n",
    "def preprocess(x, y):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=1337)\n",
    "\n",
    "    x_train = x_train.to_numpy().reshape((-1, x.shape[1]))\n",
    "    x_test = x_test.to_numpy().reshape((-1, x.shape[1]))\n",
    "    y_train = np.array(y_train).reshape((-1, 1))\n",
    "    y_test = np.array(y_test).reshape((-1, 1))\n",
    "\n",
    "    np.save(\"models/datasets/x_train\", x_train)\n",
    "    np.save(\"models/datasets/x_test\", x_test)\n",
    "    np.save(\"models/datasets/y_train\", y_train)\n",
    "    np.save(\"models/datasets/y_test\", y_test)\n",
    "\n",
    "    print(x_train.shape)\n",
    "    print(x_test.shape)\n",
    "    print(y_train.shape)\n",
    "    print(y_test.shape)\n",
    "\n",
    "preprocess(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Create a neural network that can process this data and predict the outcomes of the match\n",
    "def model():\n",
    "    import matplotlib.pyplot as plt\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense, Dropout\n",
    "\n",
    "    x_train = np.load(\"models/datasets/x_train.npy\")\n",
    "    x_test = np.load(\"models/datasets/x_test.npy\")\n",
    "    y_train = np.load(\"models/datasets/y_train.npy\")\n",
    "    y_test = np.load(\"models/datasets/y_test.npy\")\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, input_shape=(x_train.shape[1],), activation=\"relu\"))\n",
    "    model.add(Dropout(0.8))\n",
    "    model.add(Dense(256, activation=\"relu\"))\n",
    "    model.add(Dense(128, activation=\"relu\"))\n",
    "    model.add(Dense(64, activation=\"relu\"))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    metrics = model.fit(x_train, y_train, batch_size=32, epochs=30, validation_data=(x_test, y_test))\n",
    "\n",
    "    evaluation = model.evaluate(x_test, y_test)\n",
    "\n",
    "    model.save(\"models/networks/small1.h5\")\n",
    "\n",
    "    model.summary()\n",
    "    print(f\"Evaluation: {evaluation}\")\n",
    "\n",
    "    plt.plot(metrics.history[\"accuracy\"])\n",
    "    plt.plot(metrics.history[\"val_accuracy\"])\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.legend([\"Train\", \"Val\"])\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(metrics.history[\"loss\"])\n",
    "    plt.plot(metrics.history[\"val_loss\"])\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.legend([\"Traing\", \"Val\"])\n",
    "    plt.show()\n",
    "\n",
    "model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As you can see this model is pretty shit. This is propably because there is still multi_colinearity in the data.\n",
    "\n",
    "# We will try to remove more columns from x, and see what happends.\n",
    "# We will eliminate how much fighters attack, so that we are left with the quality of each type of attack.\n",
    "\n",
    "dropcol = []\n",
    "\n",
    "for c in x.columns:\n",
    "    if c.endswith(\"att\"):\n",
    "        dropcol.append(c)\n",
    "\n",
    "\n",
    "print(dropcol)\n",
    "x = x.drop(dropcol, axis=1)\n",
    "\n",
    "preprocess(x, y)\n",
    "model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So I added more dropout and the model is actually much better. It's still not reliable but after adjusting the network we can see inprovements in performance"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37564bit8153ed8c25bd45b7b4519484779c0773",
   "display_name": "Python 3.7.5 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}